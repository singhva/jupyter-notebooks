{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import json\n",
    "from watson_developer_cloud import AlchemyLanguageV1\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/singhv/Documents/Curation/thesaurus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_KEY = 'e0759019e81f7776b95cbebf8b2f2ffe0244a3f9'\n",
    "MODEL_ID = '12fc2544-de5e-44bb-937f-a775e61e7c63'\n",
    "alchemy_language = AlchemyLanguageV1(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concept name', 'parents', 'synonyms', 'definition', 'display name', 'concept status', 'semantic type']\n"
     ]
    }
   ],
   "source": [
    "temp = \"code <tab> concept name <tab> parents <tab> synonyms <tab> definition <tab> display name <tab> concept status <tab> semantic type <EOL>\"\n",
    "headers = [x.strip() for x in temp[11:-5].split(\"<tab>\")]\n",
    "print headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thesaurus = pd.read_csv(os.path.join(base_dir, \"Thesaurus.txt\"), sep=\"\\t\", index_col=0, names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows\n",
      "Processed 1000 rows\n",
      "Processed 2000 rows\n",
      "Processed 3000 rows\n",
      "Processed 4000 rows\n",
      "Processed 5000 rows\n",
      "Processed 6000 rows\n",
      "Processed 7000 rows\n",
      "Processed 8000 rows\n",
      "Processed 9000 rows\n",
      "Processed 10000 rows\n",
      "Processed 11000 rows\n",
      "Processed 12000 rows\n",
      "Processed 13000 rows\n",
      "Processed 14000 rows\n",
      "Processed 15000 rows\n",
      "Processed 16000 rows\n",
      "Processed 17000 rows\n",
      "Processed 18000 rows\n",
      "Processed 19000 rows\n",
      "Processed 20000 rows\n",
      "Processed 21000 rows\n",
      "Processed 22000 rows\n",
      "Processed 23000 rows\n",
      "Processed 24000 rows\n",
      "Processed 25000 rows\n",
      "Processed 26000 rows\n",
      "Processed 27000 rows\n",
      "Processed 28000 rows\n",
      "Processed 29000 rows\n",
      "Processed 30000 rows\n",
      "Processed 31000 rows\n",
      "Processed 32000 rows\n",
      "Processed 33000 rows\n",
      "Processed 34000 rows\n",
      "Processed 35000 rows\n",
      "Processed 36000 rows\n",
      "Processed 37000 rows\n",
      "Processed 38000 rows\n",
      "Processed 39000 rows\n",
      "Processed 40000 rows\n",
      "Processed 41000 rows\n",
      "Processed 42000 rows\n",
      "Processed 43000 rows\n",
      "Processed 44000 rows\n",
      "Processed 45000 rows\n",
      "Processed 46000 rows\n",
      "Processed 47000 rows\n",
      "Processed 48000 rows\n",
      "Processed 49000 rows\n",
      "Processed 50000 rows\n",
      "Processed 51000 rows\n",
      "Processed 52000 rows\n",
      "Processed 53000 rows\n",
      "Processed 54000 rows\n",
      "Processed 55000 rows\n",
      "Processed 56000 rows\n",
      "Processed 57000 rows\n",
      "Processed 58000 rows\n",
      "Processed 59000 rows\n",
      "Processed 60000 rows\n",
      "Processed 61000 rows\n",
      "Processed 62000 rows\n",
      "Processed 63000 rows\n",
      "Processed 64000 rows\n",
      "Processed 65000 rows\n",
      "Processed 66000 rows\n",
      "Processed 67000 rows\n",
      "Processed 68000 rows\n",
      "Processed 69000 rows\n",
      "Processed 70000 rows\n",
      "Processed 71000 rows\n",
      "Processed 72000 rows\n",
      "Processed 73000 rows\n",
      "Processed 74000 rows\n",
      "Processed 75000 rows\n",
      "Processed 76000 rows\n",
      "Processed 77000 rows\n",
      "Processed 78000 rows\n",
      "Processed 79000 rows\n",
      "Processed 80000 rows\n",
      "Processed 81000 rows\n",
      "Processed 82000 rows\n",
      "Processed 83000 rows\n",
      "Processed 84000 rows\n",
      "Processed 85000 rows\n",
      "Processed 86000 rows\n",
      "Processed 87000 rows\n",
      "Processed 88000 rows\n",
      "Processed 89000 rows\n",
      "Processed 90000 rows\n",
      "Processed 91000 rows\n",
      "Processed 92000 rows\n",
      "Processed 93000 rows\n",
      "Processed 94000 rows\n",
      "Processed 95000 rows\n",
      "Processed 96000 rows\n",
      "Processed 97000 rows\n",
      "Processed 98000 rows\n",
      "Processed 99000 rows\n",
      "Processed 100000 rows\n",
      "Processed 101000 rows\n",
      "Processed 102000 rows\n",
      "Processed 103000 rows\n",
      "Processed 104000 rows\n",
      "Processed 105000 rows\n",
      "Processed 106000 rows\n",
      "Processed 107000 rows\n",
      "Processed 108000 rows\n",
      "Processed 109000 rows\n",
      "Processed 110000 rows\n",
      "Processed 111000 rows\n",
      "Processed 112000 rows\n",
      "Processed 113000 rows\n",
      "Processed 114000 rows\n",
      "Processed 115000 rows\n",
      "Processed 116000 rows\n",
      "Processed 117000 rows\n",
      "Processed 118000 rows\n",
      "Processed 119000 rows\n",
      "Processed 120000 rows\n",
      "Processed 121000 rows\n",
      "Processed 122000 rows\n",
      "Processed 123000 rows\n",
      "Processed 124000 rows\n"
     ]
    }
   ],
   "source": [
    "for i, (code, row) in enumerate(thesaurus.iterrows()):\n",
    "    if i % 1000 == 0:\n",
    "        print \"Processed %d rows\" % i\n",
    "    parent_codes = row.get('parents')\n",
    "    if code not in G:\n",
    "        G.add_node(code)\n",
    "    G.node[code]['name'] = row['concept name']\n",
    "    G.node[code]['synonyms'] = row.get('synonyms', '').split('|')\n",
    "    if parent_codes != 'root_node':\n",
    "        parent_codes = parent_codes.split(\"|\")\n",
    "        for parent_code in parent_codes:\n",
    "            if (parent_code not in G):\n",
    "                G.add_node(parent_code)\n",
    "            G.add_edge(parent_code, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bigrams(lst):\n",
    "    return zip( lst[:-1], lst[1:] ) if len(lst) > 1 else ([(lst[0], )] if len(lst) == 1 else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C3771', 'C9134', 'C3995', 'C5141', 'C7768', 'C2924', 'C88375', 'C5166', 'C88376', 'C5214', 'C5164', 'C27829', 'C5163', 'C5160', 'C90513', 'C4001', 'C2918', 'C4194', 'C4190', 'C3641', 'C7950', 'C36085', 'C9245', 'C53553', 'C28432', 'C8287', 'C5175', 'C5177', 'C7769', 'C4017', 'C40347', 'C47857', 'C7688', 'C3862', 'C27832', 'C91230', 'C47858', 'C4872', 'C40361', 'C40364', 'C76328', 'C4190', 'C6870', 'C28311', 'C36301', 'C36300', 'C36303', 'C36302', 'C5140', 'C5454', 'C5455', 'C66933', 'C5137', 'C5138', 'C7949', 'C9456', 'C9457', 'C85835', 'C85836', 'C5167', 'C5168', 'C7782', 'C88377', 'C7770', 'C3771', 'C47857', 'C40354', 'C5160', 'C4017', 'C40360', 'C5163', 'C40364', 'C27831', 'C27830', 'C27832', 'C6987', 'C7690', 'C7767', 'C7769', 'C7696', 'C9246', 'C8607', 'C36107', 'C40351', 'C40350', 'C9132', 'C7362', 'C7645', 'C5139', 'C4195', 'C4018', 'C2924', 'C9136', 'C54691', 'C97049', 'C97051', 'C97052', 'C97053', 'C36084', 'C7439', 'C9135', 'C4189', 'C9131', 'C97965', 'C5142', 'C7950', 'C9119', 'C6760', 'C40349', 'C40395', 'C5166', 'C5164', 'C4001', 'C27829', 'C40356', 'C66719', 'C4194', 'C40374', 'C7951', 'C5130', 'C36085', 'C5175', 'C5177', 'C40347', 'C40355', 'C5457', 'C40368', 'C40369', 'C40361', 'C40366', 'C40367', 'C40365', 'C53558', 'C71732', 'C53555', 'C53554', 'C53557', 'C53556', 'C3301', 'C28292', 'C27234', 'C40370', 'C99390', 'C5176', 'C40359', 'C40358', 'C40357', 'C5178', 'C27828', 'C9134', 'C5141', 'C76326', 'C6939', 'C7688', 'C47858', 'C7689', 'C6393', 'C36106', 'C5161', 'C3641', 'C88375', 'C88376', 'C3995', 'C7768', 'C4019', 'C94774', 'C7566', 'C8287', 'C94770', 'C9245', 'C2918', 'C118809', 'C53553', 'C3862', 'C94772', 'C4503', 'C28432', 'C91230', 'C5214', 'C7771', 'C46073', 'C90513', 'C40362', 'C47848', 'C47847']\n"
     ]
    }
   ],
   "source": [
    "#print nx.dfs_successors(G, 'C4872')\n",
    "successors = nx.dfs_successors(G, 'C4872')\n",
    "successors_codes = successors.keys() + sum(successors.values(), [])\n",
    "print successors_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C3771\n",
      "Processing C9134\n",
      "Processing C3995\n",
      "Processing C5141\n",
      "Processing C7768\n",
      "Processing C2924\n",
      "Processing C88375\n",
      "Processing C5166\n",
      "Processing C88376\n",
      "Processing C5214\n",
      "Processing C5164\n",
      "Processing C27829\n",
      "Processing C5163\n",
      "Processing C5160\n",
      "Processing C90513\n",
      "Processing C4001\n",
      "Processing C2918\n",
      "Processing C4194\n",
      "Processing C4190\n",
      "Processing C3641\n",
      "Processing C7950\n",
      "Processing C36085\n",
      "Processing C9245\n",
      "Processing C53553\n",
      "Processing C28432\n",
      "Processing C8287\n",
      "Processing C5175\n",
      "Processing C5177\n",
      "Processing C7769\n",
      "Processing C4017\n",
      "Processing C40347\n",
      "Processing C47857\n",
      "Processing C7688\n",
      "Processing C3862\n",
      "Processing C27832\n",
      "Processing C91230\n",
      "Processing C47858\n",
      "Processing C4872\n",
      "Processing C40361\n",
      "Processing C40364\n",
      "Processing C76328\n",
      "Processing C4190\n",
      "Processing C6870\n",
      "Processing C28311\n",
      "Processing C36301\n",
      "Processing C36300\n",
      "Processing C36303\n",
      "Processing C36302\n",
      "Processing C5140\n",
      "Processing C5454\n",
      "Processing C5455\n",
      "Processing C66933\n",
      "Processing C5137\n",
      "Processing C5138\n",
      "Processing C7949\n",
      "Processing C9456\n",
      "Processing C9457\n",
      "Processing C85835\n",
      "Processing C85836\n",
      "Processing C5167\n",
      "Processing C5168\n",
      "Processing C7782\n",
      "Processing C88377\n",
      "Processing C7770\n",
      "Processing C3771\n",
      "Processing C47857\n",
      "Processing C40354\n",
      "Processing C5160\n",
      "Processing C4017\n",
      "Processing C40360\n",
      "Processing C5163\n",
      "Processing C40364\n",
      "Processing C27831\n",
      "Processing C27830\n",
      "Processing C27832\n",
      "Processing C6987\n",
      "Processing C7690\n",
      "Processing C7767\n",
      "Processing C7769\n",
      "Processing C7696\n",
      "Processing C9246\n",
      "Processing C8607\n",
      "Processing C36107\n",
      "Processing C40351\n",
      "Processing C40350\n",
      "Processing C9132\n",
      "Processing C7362\n",
      "Processing C7645\n",
      "Processing C5139\n",
      "Processing C4195\n",
      "Processing C4018\n",
      "Processing C2924\n",
      "Processing C9136\n",
      "Processing C54691\n",
      "Processing C97049\n",
      "Processing C97051\n",
      "Processing C97052\n",
      "Processing C97053\n",
      "Processing C36084\n",
      "Processing C7439\n",
      "Processing C9135\n",
      "Processing C4189\n",
      "Processing C9131\n",
      "Processing C97965\n",
      "Processing C5142\n",
      "Processing C7950\n",
      "Processing C9119\n",
      "Processing C6760\n",
      "Processing C40349\n",
      "Processing C40395\n",
      "Processing C5166\n",
      "Processing C5164\n",
      "Processing C4001\n",
      "Processing C27829\n",
      "Processing C40356\n",
      "Processing C66719\n",
      "Processing C4194\n",
      "Processing C40374\n",
      "Processing C7951\n",
      "Processing C5130\n",
      "Processing C36085\n",
      "Processing C5175\n",
      "Processing C5177\n",
      "Processing C40347\n",
      "Processing C40355\n",
      "Processing C5457\n",
      "Processing C40368\n",
      "Processing C40369\n",
      "Processing C40361\n",
      "Processing C40366\n",
      "Processing C40367\n",
      "Processing C40365\n",
      "Processing C53558\n",
      "Processing C71732\n",
      "Processing C53555\n",
      "Processing C53554\n",
      "Processing C53557\n",
      "Processing C53556\n",
      "Processing C3301\n",
      "Processing C28292\n",
      "Processing C27234\n",
      "Processing C40370\n",
      "Processing C99390\n",
      "Processing C5176\n",
      "Processing C40359\n",
      "Processing C40358\n",
      "Processing C40357\n",
      "Processing C5178\n",
      "Processing C27828\n",
      "Processing C9134\n",
      "Processing C5141\n",
      "Processing C76326\n",
      "Processing C6939\n",
      "Processing C7688\n",
      "Processing C47858\n",
      "Processing C7689\n",
      "Processing C6393\n",
      "Processing C36106\n",
      "Processing C5161\n",
      "Processing C3641\n",
      "Processing C88375\n",
      "Processing C88376\n",
      "Processing C3995\n",
      "Processing C7768\n",
      "Processing C4019\n",
      "Processing C94774\n",
      "Processing C7566\n",
      "Processing C8287\n",
      "Processing C94770\n",
      "Processing C9245\n",
      "Processing C2918\n",
      "Processing C118809\n",
      "Processing C53553\n",
      "Processing C3862\n",
      "Processing C94772\n",
      "Processing C4503\n",
      "Processing C28432\n",
      "Processing C91230\n",
      "Processing C5214\n",
      "Processing C7771\n",
      "Processing C46073\n",
      "Processing C90513\n",
      "Processing C40362\n",
      "Processing C47848\n",
      "Processing C47847\n"
     ]
    }
   ],
   "source": [
    "bigrams = []\n",
    "successors = nx.dfs_successors(G, 'C4872')\n",
    "for node_code in successors.keys() + sum(successors.values(), []):\n",
    "    print \"Processing %s\" % (node_code)\n",
    "    node = G.node[node_code]\n",
    "    synonyms = node[\"synonyms\"]\n",
    "    for name in synonyms:\n",
    "        json_result = alchemy_language.entities(model=MODEL_ID, text=name, language='english')\n",
    "        if json_result and json_result.get(\"status\") == \"OK\":\n",
    "            entities = [ x[\"type\"] for x in json_result[\"entities\"] ]\n",
    "            bigrams.extend(make_bigrams(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n"
     ]
    }
   ],
   "source": [
    "print len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anatomy_Specific_Entity AND Cancer_Entity (459)\n",
      "Cancer_Entity AND Anatomy_Specific_Entity (248)\n",
      "Tissue_Entity AND Cancer_Entity (234)\n",
      "Locomotive_Modifier_Entity AND Tissue_Entity (87)\n",
      "Stage_Entity AND Anatomy_Specific_Entity (72)\n",
      "Tissue_Entity AND Anatomy_Specific_Entity (61)\n",
      "Anatomy_Specific_Entity (60)\n",
      "Locomotive_Modifier_Entity AND Anatomy_Specific_Entity (41)\n",
      "Cancer_Entity (25)\n",
      "Cancer_Entity AND Stage_Entity (22)\n",
      "Disease_Entity AND Anatomy_Specific_Entity (22)\n",
      "Disease_Modifier_Entity AND Anatomy_Specific_Entity (15)\n",
      "Tissue_Entity AND Tissue_Entity (15)\n",
      "Locomotive_Modifier_Entity AND Cancer_Entity (14)\n",
      "Anatomy_Specific_Entity AND Tissue_Entity (14)\n",
      "Cancer_Entity AND Disease_Modifier_Entity (12)\n",
      "Finding_Lesion_Entity AND Tissue_Entity (12)\n",
      "Cancer_Entity AND Tissue_Entity (8)\n",
      "Disease_Modifier_Entity AND Tissue_Entity (7)\n",
      "Anatomy_Specific_Entity AND Locomotive_Modifier_Entity (7)\n",
      "Anatomy_Specific_Entity AND Anatomy_Specific_Entity (6)\n",
      "Pos_Neg_Entity AND Anatomy_Specific_Entity (6)\n",
      "Anatomy_Specific_Entity AND Stage_Entity (6)\n",
      "Spatial_Modifier_Entity AND Anatomy_Specific_Entity (6)\n",
      "Cancer_Entity AND Locomotive_Modifier_Entity (5)\n",
      "Finding_Lesion_Entity AND Cancer_Entity (4)\n",
      "Tissue_Entity AND Locomotive_Modifier_Entity (4)\n",
      "Finding_Lesion_Entity AND Anatomy_Specific_Entity (4)\n",
      "Quantity_Entity AND Cancer_Entity (4)\n",
      "Disease_Entity AND Cancer_Entity (2)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(bigrams)\n",
    "df = pd.DataFrame(columns=['Bigram', 'Count'])\n",
    "#print counter\n",
    "count = 0\n",
    "for (bigram, count) in counter.most_common(30):\n",
    "    print \"%s (%d)\" % (\" AND \".join(bigram), count)\n",
    "    df.loc[count] = (\" AND \".join(bigram), count)\n",
    "    count += 1\n",
    "    \n",
    "df.to_excel(\"/Users/singhv/Desktop/BigramEntityFrequency.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_result = alchemy_language.entities(model=MODEL_ID, text='Breast Columnar Cell Mucinous Carcinoma', language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'status': u'OK', u'usage': u'By accessing AlchemyAPI or using information generated by AlchemyAPI, you are agreeing to be bound by the AlchemyAPI Terms of Use: http://www.alchemyapi.com/company/terms.html', u'model': u'12fc2544-de5e-44bb-937f-a775e61e7c63', u'language': u'english', u'entities': [{u'count': u'1', u'text': u'Breast', u'type': u'Anatomy_Specific_Entity'}, {u'count': u'1', u'text': u'Mucinous', u'type': u'Tissue_Entity'}, {u'count': u'1', u'text': u'Carcinoma', u'type': u'Cancer_Entity'}]}\n"
     ]
    }
   ],
   "source": [
    "print json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': u'1', u'text': u'Carcinoma', u'type': u'Cancer_Entity'}, {u'count': u'1', u'text': u'Invasive', u'type': u'Locomotive_Modifier_Entity'}, {u'count': u'1', u'text': u'Lobular', u'type': u'Tissue_Entity'}, {u'count': u'1', u'text': u'mammary', u'type': u'Anatomy_Specific_Entity'}]\n"
     ]
    }
   ],
   "source": [
    "print json_result[\"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
